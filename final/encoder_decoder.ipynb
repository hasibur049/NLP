{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hasibur1\\Anaconda3_\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  \n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import string\n",
    "from string import digits\n",
    "from pandas import Panel\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as et \n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU, LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hasibur1\\Anaconda3_\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd \n",
    "import pandas as pd \n",
    "   \n",
    "# Takes the file's folder \n",
    "filepath = r\"C:Documents\\dataset.csv\"\n",
    "# read the CSV file \n",
    "lines = pd.read_csv(filepath, sep='delimiter', header=None) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['qa']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(lines)) \n",
    "lines.columns = ['qa']\n",
    "list(lines.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[['question','answer']] = lines.qa.apply(lambda x: pd.Series(str(x).split(\"?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qa', 'question', 'answer']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lines.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in lines.columns: \n",
    "    if 'qa' in col: \n",
    "        del lines[col] \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>What is (are) abdominal wall defect</td>\n",
       "      <td>,An opening in the abdomen through which vario...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>What are the treatments for abdominal wall defect</td>\n",
       "      <td>,Diagnostic Tests-Drug Therapy-Surgery and Reh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>What is (are) Osteoporosis</td>\n",
       "      <td>,A Bone Disease that thins and weakens the bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Who is at risk for Osteoporosis</td>\n",
       "      <td>,Women are at higher risk for osteoporosis tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>What are the symptoms of Osteoporosis</td>\n",
       "      <td>,Fractures-A Possible Warning Sign Osteoporosi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                What is (are) abdominal wall defect   \n",
       "1  What are the treatments for abdominal wall defect   \n",
       "2                        What is (are) Osteoporosis    \n",
       "3                    Who is at risk for Osteoporosis   \n",
       "4             What are the symptoms of Osteoporosis    \n",
       "\n",
       "                                              answer  \n",
       "0  ,An opening in the abdomen through which vario...  \n",
       "1  ,Diagnostic Tests-Drug Therapy-Surgery and Reh...  \n",
       "2  ,A Bone Disease that thins and weakens the bon...  \n",
       "3  ,Women are at higher risk for osteoporosis tha...  \n",
       "4  ,Fractures-A Possible Warning Sign Osteoporosi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.columns = ['source', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['target'] = lines['target'].fillna('').apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert source and target text to Lowercase \n",
    "lines.source=lines.source.apply(lambda x: x.lower())\n",
    "lines.target=lines.target.apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes from source and target text\n",
    "lines.source=lines.source.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.target=lines.target.apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "# create a set of all special characters\n",
    "special_characters= set(string.punctuation)\n",
    "\n",
    "# Remove all the special characters\n",
    "lines.source = lines.source.apply(lambda x: ''.join(char1 for char1 in x if char1 not in special_characters))\n",
    "lines.target = lines.target.apply(lambda x: ''.join(char1 for char1 in x if char1 not in special_characters))\n",
    "\n",
    "# Remove digits from source and target sentences\n",
    "num_digits= str.maketrans('','', digits)\n",
    "lines.source=lines.source.apply(lambda x: x.translate(num_digits))\n",
    "lines.target= lines.target.apply(lambda x: x.translate(num_digits))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines.source=lines.source.apply(lambda x: x.strip())\n",
    "lines.target=lines.target.apply(lambda x: x.strip())\n",
    "lines.source=lines.source.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.target=lines.target.apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1326</td>\n",
       "      <td>what research or clinical trials is being done...</td>\n",
       "      <td>START_ multiple studies are looking at ways to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>742</td>\n",
       "      <td>how many people are affected by phosphoribosyl...</td>\n",
       "      <td>START_ prs superactivity is believed to be a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1042</td>\n",
       "      <td>is aarskogscott syndrome inherited</td>\n",
       "      <td>START_ aarskogscott syndrome is inherited in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3148</td>\n",
       "      <td>what is are snyderrobinson syndrome</td>\n",
       "      <td>START_ a condition characterized by intellectu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>how many people are affected by peutzjeghers s...</td>\n",
       "      <td>START_ the prevalence of this condition is unc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3908</td>\n",
       "      <td>is beta hydroxysteroid dehydrogenase deficienc...</td>\n",
       "      <td>START_ this condition is inherited in an autos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "1326  what research or clinical trials is being done...   \n",
       "742   how many people are affected by phosphoribosyl...   \n",
       "1042                 is aarskogscott syndrome inherited   \n",
       "3148                what is are snyderrobinson syndrome   \n",
       "715   how many people are affected by peutzjeghers s...   \n",
       "3908  is beta hydroxysteroid dehydrogenase deficienc...   \n",
       "\n",
       "                                                 target  \n",
       "1326  START_ multiple studies are looking at ways to...  \n",
       "742   START_ prs superactivity is believed to be a r...  \n",
       "1042  START_ aarskogscott syndrome is inherited in a...  \n",
       "3148  START_ a condition characterized by intellectu...  \n",
       "715   START_ the prevalence of this condition is unc...  \n",
       "3908  START_ this condition is inherited in an autos...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines.target = lines.target.apply(lambda x : 'START_ '+ x + ' _END')\n",
    "lines.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1193, 3880)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the source and target words and sort them\n",
    "# Vocabulary of Source language\n",
    "all_source_words=set()\n",
    "for source in lines.source:\n",
    "    for word in source.split():\n",
    "        if word not in all_source_words:\n",
    "            all_source_words.add(word)\n",
    "# Vocabulary of Target \n",
    "all_target_words=set()\n",
    "for target in lines.target:\n",
    "    for word in target.split():\n",
    "        if word not in all_target_words:\n",
    "            all_target_words.add(word)\n",
    "# sort all unique source and target words\n",
    "source_words= sorted(list(all_source_words))\n",
    "target_words=sorted(list(all_target_words))\n",
    "\n",
    "len(source_words), len(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Max length of the source sentence 18\n",
      " Max length of the target sentence 31\n"
     ]
    }
   ],
   "source": [
    "#Find maximum sentence length in  the source and target data\n",
    "source_length_list=[]\n",
    "for l in lines.source:\n",
    "    source_length_list.append(len(l.split(' ')))\n",
    "max_source_length= max(source_length_list)\n",
    "print(\" Max length of the source sentence\",max_source_length)\n",
    "target_length_list=[]\n",
    "for l in lines.target:\n",
    "    target_length_list.append(len(l.split(' ')))\n",
    "max_target_length= max(target_length_list)\n",
    "print(\" Max length of the target sentence\",max_target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a word to index(word2idx) for source and target\n",
    "source_word2idx= dict([(word, i+1) for i,word in enumerate(source_words)])\n",
    "target_word2idx=dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'aarskogscott', 3: 'ab', 4: 'abdominal', 5: 'abetalipoproteinemia', 6: 'abnormal', 7: 'abuse', 8: 'acatalasemia', 9: 'achondrogenesis', 10: 'achondroplasia', 11: 'achromatopsia', 12: 'acid', 13: 'acidemia', 14: 'acidosis', 15: 'aciduria', 16: 'acral', 17: 'acrofacial', 18: 'acromicric', 19: 'actinaccumulation', 20: 'activated', 21: 'acute', 22: 'acylcoa', 23: 'adamsoliver', 24: 'adcyrelated', 25: 'adenine', 26: 'adenosine', 27: 'adenylosuccinate', 28: 'adermatoglyphia', 29: 'adhesion', 30: 'adiposis', 31: 'adolescent', 32: 'adrenal', 33: 'adrenoleukodystrophy', 34: 'adult', 35: 'adultonset', 36: 'adults', 37: 'affected', 38: 'african', 39: 'agammaglobulinemia', 40: 'agerelated', 41: 'aggregate', 42: 'aicardi', 43: 'aicardigoutieres', 44: 'aidsrelated', 45: 'alagille', 46: 'albinism', 47: 'alexander', 48: 'algcongenital', 49: 'alkaptonuria', 50: 'allanherndondudley', 51: 'allergic', 52: 'alopecia', 53: 'alopeciaand', 54: 'alpershuttenlocher', 55: 'alpha', 56: 'alphabeta', 57: 'alphahydroxylaselyase', 58: 'alphamannosidosis', 59: 'american', 60: 'amyloid', 61: 'amyloidosis', 62: 'amyotrophy', 63: 'and', 64: 'anemia', 65: 'angioedema', 66: 'angiopathy', 67: 'anomalies', 68: 'anophthalmia', 69: 'antithrombin', 70: 'antitrypsin', 71: 'aortic', 72: 'aplasia', 73: 'appears', 74: 'are', 75: 'arterial', 76: 'arteriosclerosis', 77: 'arthritis', 78: 'arthropathy', 79: 'ascending', 80: 'assembly', 81: 'association', 82: 'asthma', 83: 'at', 84: 'ataxia', 85: 'atrophy', 86: 'attack', 87: 'autonomic', 88: 'axonal', 89: 'balance', 90: 'batten', 91: 'being', 92: 'beta', 93: 'betaglobin', 94: 'betahydroxysteroid', 95: 'bifida', 96: 'bile', 97: 'blindness', 98: 'blood', 99: 'bodies', 100: 'body', 101: 'bone', 102: 'brain', 103: 'brainstem', 104: 'breakage', 105: 'breast', 106: 'bulbar', 107: 'bullosa', 108: 'by', 109: 'calcification', 110: 'cancer', 111: 'carboxylase', 112: 'carcinoid', 113: 'carcinoma', 114: 'cause', 115: 'causes', 116: 'cavity', 117: 'cell', 118: 'central', 119: 'cephalic', 120: 'cephalopolysyndactyly', 121: 'cerebellar', 122: 'cerebellaris', 123: 'cerebral', 124: 'cerebrooculofacioskeletal', 125: 'ceroid', 126: 'changes', 127: 'charcotmarietooth', 128: 'childhood', 129: 'children', 130: 'cholestasis', 131: 'chondrodysplasia', 132: 'chorea', 133: 'choroid', 134: 'chromosome', 135: 'chronic', 136: 'cidp', 137: 'cirrhosis', 138: 'clinical', 139: 'cluster', 140: 'cns', 141: 'coa', 142: 'coalition', 143: 'cofactor', 144: 'coffin', 145: 'cofs', 146: 'colitis', 147: 'collins', 148: 'coloboma', 149: 'colon', 150: 'colorectal', 151: 'colpocephaly', 152: 'coma', 153: 'combined', 154: 'complex', 155: 'complications', 156: 'confetti', 157: 'congenita', 158: 'congenital', 159: 'consequences', 160: 'cord', 161: 'corneal', 162: 'coronavirus', 163: 'corticobasal', 164: 'covid', 165: 'cramps', 166: 'craniopharyngioma', 167: 'craniosynostosis', 168: 'creatine', 169: 'creutzfeldtjakob', 170: 'cushings', 171: 'cutaneous', 172: 'cutis', 173: 'cystic', 174: 'cysts', 175: 'cytomegalovirus', 176: 'dandywalker', 177: 'ddependent', 178: 'de', 179: 'deafness', 180: 'deaminase', 181: 'death', 182: 'decarboxylase', 183: 'deep', 184: 'defect', 185: 'defectepsteinbarr', 186: 'defects', 187: 'deficiency', 188: 'degeneration', 189: 'dehydrogenase', 190: 'deletion', 191: 'dementia', 192: 'demyelinating', 193: 'depletion', 194: 'der', 195: 'dermatomyositis', 196: 'development', 197: 'developmental', 198: 'diabetes', 199: 'diabetic', 200: 'diagnose', 201: 'diagonose', 202: 'diagonse', 203: 'diffuse', 204: 'disability', 205: 'disabilitysiderius', 206: 'disease', 207: 'diseaselike', 208: 'disorder', 209: 'disorders', 210: 'distal', 211: 'distress', 212: 'dna', 213: 'do', 214: 'does', 215: 'dolorosa', 216: 'done', 217: 'dravet', 218: 'drop', 219: 'drug', 220: 'duane', 221: 'duct', 222: 'duplication', 223: 'dwarfism', 224: 'dysfunction', 225: 'dysfunctions', 226: 'dysgenesis', 227: 'dysgraphia', 228: 'dyskinesia', 229: 'dyslexia', 230: 'dysostosis', 231: 'dysplasia', 232: 'dysplasiastrudwick', 233: 'dyspraxia', 234: 'dysregulation', 235: 'dyssynergia', 236: 'dystonia', 237: 'dystoniaparkinsonism', 238: 'dystoniapolycythemia', 239: 'dystonias', 240: 'dystrophy', 241: 'early', 242: 'earlyonset', 243: 'ectopia', 244: 'elevation', 245: 'empty', 246: 'encephalitis', 247: 'encephaloceles', 248: 'encephalomyopathy', 249: 'encephalopathy', 250: 'endocrine', 251: 'endometrial', 252: 'endothelial', 253: 'enteropathy', 254: 'enzyme', 255: 'eosinophilic', 256: 'ependymoma', 257: 'epidermal', 258: 'epidermolysis', 259: 'epilepsy', 260: 'epiphyseal', 261: 'episodes', 262: 'epithelial', 263: 'epsteinbarr', 264: 'erythematosus', 265: 'erythroderma', 266: 'essential', 267: 'ewing', 268: 'extracranial', 269: 'extragonadal', 270: 'fabry', 271: 'factor', 272: 'factors', 273: 'fahrs', 274: 'failure', 275: 'familial', 276: 'farbers', 277: 'febrile', 278: 'fiber', 279: 'fibers', 280: 'fibromatosis', 281: 'fibromuscular', 282: 'fibrosis', 283: 'fibrous', 284: 'fisher', 285: 'focal', 286: 'folate', 287: 'foot', 288: 'for', 289: 'form', 290: 'formiminotransferase', 291: 'friedreich', 292: 'friedreichs', 293: 'frontometaphyseal', 294: 'frontonasal', 295: 'frontotemporal', 296: 'fructose', 297: 'fryns', 298: 'fuchs', 299: 'fucosidosis', 300: 'fukuyama', 301: 'fumarase', 302: 'fungoides', 303: 'galactosemia', 304: 'galactosialidosis', 305: 'gamma', 306: 'gangliosidoses', 307: 'gangliosidosis', 308: 'gastric', 309: 'gastrointestinal', 310: 'gaucher', 311: 'gaze', 312: 'gbbb', 313: 'geleophysic', 314: 'generalized', 315: 'genetic', 316: 'genital', 317: 'genitalia', 318: 'genitopatellar', 319: 'germ', 320: 'gerstmanns', 321: 'gerstmannstrausslerscheinker', 322: 'gestational', 323: 'ghosal', 324: 'giant', 325: 'gilbert', 326: 'gillespie', 327: 'gitelman', 328: 'gland', 329: 'glanzmann', 330: 'glia', 331: 'glioma', 332: 'globozoospermia', 333: 'globulin', 334: 'glossopharyngeal', 335: 'glucose', 336: 'glucosegalactose', 337: 'glucosephosphate', 338: 'glut', 339: 'glutamate', 340: 'glutaric', 341: 'glutathione', 342: 'glycine', 343: 'glycogen', 344: 'glycosylation', 345: 'gm', 346: 'gmgangliosidosis', 347: 'gmgangliosidosisab', 348: 'gnathodiaphyseal', 349: 'gorlin', 350: 'gracile', 351: 'granulomatosis', 352: 'graves', 353: 'gravis', 354: 'gray', 355: 'greenberg', 356: 'greig', 357: 'griscelli', 358: 'grnrelated', 359: 'growth', 360: 'guanidinoacetate', 361: 'guillainbarr', 362: 'gyrate', 363: 'hair', 364: 'hairy', 365: 'hajducheney', 366: 'handfootgenital', 367: 'harlequin', 368: 'hashimoto', 369: 'head', 370: 'hearing', 371: 'heart', 372: 'hematodiaphyseal', 373: 'hemifacial', 374: 'hemiplegic', 375: 'hemochromatosis', 376: 'hemophilia', 377: 'hemorrhagic', 378: 'hennekam', 379: 'hepatic', 380: 'hepatocerebral', 381: 'hereditary', 382: 'hermanskypudlak', 383: 'heterotaxy', 384: 'hidradenitis', 385: 'high', 386: 'hippellindau', 387: 'hirschsprung', 388: 'histidinemia', 389: 'histiocytoma', 390: 'histiocytosis', 391: 'histiocytosislymphadenopathy', 392: 'hodgkin', 393: 'holocarboxylase', 394: 'holoprosencephaly', 395: 'holtoram', 396: 'homocystinuria', 397: 'horizontal', 398: 'hormone', 399: 'horner', 400: 'how', 401: 'huntington', 402: 'hutchinsongilford', 403: 'hyaline', 404: 'hyalinosis', 405: 'hydratase', 406: 'hydroxyacylcoa', 407: 'hydroxyglutaric', 408: 'hydroxylase', 409: 'hydroxymethylglutarylcoa', 410: 'hydroxysteroid', 411: 'hyper', 412: 'hypercholesterolemia', 413: 'hyperekplexia', 414: 'hyperferritinemiacataract', 415: 'hyperkalemic', 416: 'hyperlysinemia', 417: 'hypermanganesemia', 418: 'hypermethioninemia', 419: 'hyperparathyroidismjaw', 420: 'hyperthermia', 421: 'hypertrophy', 422: 'hypopharyngeal', 423: 'hypophosphatemic', 424: 'hypoplasia', 425: 'hypotonia', 426: 'hypouricemia', 427: 'hystrixlike', 428: 'i', 429: 'ia', 430: 'ichthyosiform', 431: 'ichthyosis', 432: 'idiopathic', 433: 'idsrelated', 434: 'ie', 435: 'igm', 436: 'ii', 437: 'iii', 438: 'iiirelated', 439: 'illicit', 440: 'imerslundgrsbeck', 441: 'immune', 442: 'immunodeficiency', 443: 'immunodeficiencycongenital', 444: 'immunoosseous', 445: 'in', 446: 'inclusion', 447: 'incontinence', 448: 'incontinentia', 449: 'indian', 450: 'infancy', 451: 'infant', 452: 'infantile', 453: 'infantileonset', 454: 'infection', 455: 'infectionand', 456: 'infections', 457: 'infertility', 458: 'inflammatory', 459: 'inherited', 460: 'insipidus', 461: 'insulin', 462: 'intellectual', 463: 'intestinal', 464: 'intestine', 465: 'intolerance', 466: 'intrahepatic', 467: 'intranuclear', 468: 'intraocular', 469: 'intrauterine', 470: 'involvement', 471: 'irak', 472: 'iron', 473: 'ironrefractory', 474: 'ironsulfur', 475: 'is', 476: 'isobutyrylcoa', 477: 'isodicentric', 478: 'isolated', 479: 'isomerase', 480: 'isovaleric', 481: 'it', 482: 'iv', 483: 'ix', 484: 'jacksonweiss', 485: 'jacobsen', 486: 'jervell', 487: 'joubert', 488: 'junctional', 489: 'juvenile', 490: 'kabuki', 491: 'kallmann', 492: 'kawasaki', 493: 'kbg', 494: 'kearnssayre', 495: 'keratitisichthyosisdeafness', 496: 'keratoderma', 497: 'kidney', 498: 'kinase', 499: 'kleefstra', 500: 'klinefelter', 501: 'klippelfeil', 502: 'klippeltrenaunay', 503: 'kniest', 504: 'knobloch', 505: 'koolende', 506: 'krabbe', 507: 'kufs', 508: 'kuskokwim', 509: 'l', 510: 'lacrimoauriculodentodigital', 511: 'lactate', 512: 'lactic', 513: 'lactose', 514: 'lafora', 515: 'laing', 516: 'lamarelated', 517: 'lamellar', 518: 'langenielsen', 519: 'langer', 520: 'langergiedion', 521: 'langerhans', 522: 'laron', 523: 'larsen', 524: 'laryngeal', 525: 'laryngoonychocutaneous', 526: 'lateinfantile', 527: 'lateral', 528: 'lattice', 529: 'leber', 530: 'lectin', 531: 'leggcalvperthes', 532: 'legius', 533: 'legs', 534: 'leigh', 535: 'leiomyomatosis', 536: 'lennoxgastaut', 537: 'lentigines', 538: 'lentis', 539: 'lenz', 540: 'leptin', 541: 'leschnyhan', 542: 'lethal', 543: 'lethargica', 544: 'leukemia', 545: 'leukocyte', 546: 'leukodystrophy', 547: 'leukoencephalopathy', 548: 'lewy', 549: 'leydig', 550: 'liability', 551: 'liddle', 552: 'lifraumeni', 553: 'ligase', 554: 'likely', 555: 'limbgirdle', 556: 'linear', 557: 'lip', 558: 'lipase', 559: 'lipid', 560: 'lipofuscinosis', 561: 'lipomembranous', 562: 'lissencephaly', 563: 'liver', 564: 'loeysdietz', 565: 'longchain', 566: 'loss', 567: 'low', 568: 'lowe', 569: 'lowry', 570: 'lujan', 571: 'lung', 572: 'lupus', 573: 'lyase', 574: 'lymphangioleiomyomatosis', 575: 'lymphedemadistichiasis', 576: 'lymphoblastic', 577: 'lymphoma', 578: 'lymphoproliferative', 579: 'lynch', 580: 'lysinuric', 581: 'm', 582: 'maatkievitbrunner', 583: 'mabry', 584: 'macroaneurysm', 585: 'macroglobulinemia', 586: 'macular', 587: 'maffucci', 588: 'magnesium', 589: 'mainzersaldino', 590: 'majeed', 591: 'mal', 592: 'malabsorption', 593: 'male', 594: 'malformation', 595: 'malformations', 596: 'malignant', 597: 'mall', 598: 'malonylcoa', 599: 'mandibuloacral', 600: 'mandibulofacial', 601: 'manitoba', 602: 'mannosebinding', 603: 'many', 604: 'maple', 605: 'marfan', 606: 'marinescosjgren', 607: 'maternally', 608: 'matter', 609: 'mayerrokitanskyksterhauser', 610: 'mc', 611: 'mccunealbright', 612: 'mckusickkaufman', 613: 'mcleod', 614: 'meckel', 615: 'mecp', 616: 'mecprelated', 617: 'mediumchain', 618: 'medullary', 619: 'meesmann', 620: 'megalencephalic', 621: 'megalencephalycapillary', 622: 'megaloblastic', 623: 'megdel', 624: 'meiergorlin', 625: 'meige', 626: 'melanocytic', 627: 'melanoma', 628: 'meleda', 629: 'mellitus', 630: 'melnickneedles', 631: 'membrane', 632: 'meningitis', 633: 'menkes', 634: 'merkel', 635: 'mesomelic', 636: 'metachromatic', 637: 'metaphyseal', 638: 'metastatic', 639: 'metatropic', 640: 'methemoglobinemia', 641: 'methylbutyrylcoa', 642: 'methylcrotonylcoa', 643: 'methylglutaconylcoa', 644: 'methylmalonic', 645: 'methyltransferase', 646: 'mevalonate', 647: 'microcephalic', 648: 'microcephaly', 649: 'microcephalycapillary', 650: 'microdeletion', 651: 'microphthalmia', 652: 'microvillus', 653: 'migraine', 654: 'migrating', 655: 'miller', 656: 'millerdieker', 657: 'milroy', 658: 'minus', 659: 'mitochondrial', 660: 'miyoshi', 661: 'moebius', 662: 'molybdenum', 663: 'monilethrix', 664: 'most', 665: 'motion', 666: 'mowatwilson', 667: 'moyamoya', 668: 'mpvrelated', 669: 'mucklewells', 670: 'mucolipidosis', 671: 'mucopolysaccharidosis', 672: 'mucosal', 673: 'muenke', 674: 'multicentric', 675: 'multiinfarct', 676: 'multiminicore', 677: 'multiple', 678: 'multiplex', 679: 'multisystem', 680: 'muscle', 681: 'muscular', 682: 'mutase', 683: 'myasthenia', 684: 'mycosis', 685: 'myd', 686: 'myelitis', 687: 'myelodysplastic', 688: 'myelogenous', 689: 'myeloid', 690: 'myeloproliferative', 691: 'myhre', 692: 'myhrelated', 693: 'myoclonic', 694: 'myoclonica', 695: 'myoclonus', 696: 'myoclonusdystonia', 697: 'myofibrillar', 698: 'myopathies', 699: 'myopathy', 700: 'myosin', 701: 'myostatinrelated', 702: 'myotonia', 703: 'myotonic', 704: 'myotubular', 705: 'nacetylglutamate', 706: 'naegelifranceschettijadassohn', 707: 'nager', 708: 'nail', 709: 'nailpatella', 710: 'nakajonishimura', 711: 'narcolepsy', 712: 'nasal', 713: 'nasopharyngeal', 714: 'neck', 715: 'necrolysis', 716: 'necrosis', 717: 'nemaline', 718: 'neonatal', 719: 'neoplasia', 720: 'neoplasms', 721: 'nephrogenic', 722: 'nephronophthisis', 723: 'nephropathyaneurysms', 724: 'nervous', 725: 'netherton', 726: 'neuralgia', 727: 'neuralgic', 728: 'neuroacanthocytosis', 729: 'neuroaxonal', 730: 'neuroblastoma', 731: 'neurodegeneration', 732: 'neuroferritinopathy', 733: 'neurofibromatosis', 734: 'neurogastrointestinal', 735: 'neurohypophyseal', 736: 'neurological', 737: 'neuromyelitis', 738: 'neuronal', 739: 'neuropathy', 740: 'neutral', 741: 'neutropenia', 742: 'neutrophilic', 743: 'nevus', 744: 'nicolaidesbaraitser', 745: 'niemannpick', 746: 'night', 747: 'nijmegen', 748: 'nodulosis', 749: 'nonbullous', 750: 'nonhodgkin', 751: 'nonsmall', 752: 'nonsyndromic', 753: 'noonan', 754: 'norrie', 755: 'north', 756: 'northern', 757: 'not', 758: 'nystagmus', 759: 'occult', 760: 'ochoa', 761: 'ocular', 762: 'oculocutaneous', 763: 'oculodentodigital', 764: 'oculofaciocardiodental', 765: 'oculopharyngeal', 766: 'oculotrichoanal', 767: 'of', 768: 'ohdo', 769: 'ohtahara', 770: 'older', 771: 'ollier', 772: 'onset', 773: 'ophthalmoacromelic', 774: 'opitz', 775: 'opsoclonus', 776: 'optic', 777: 'optica', 778: 'or', 779: 'oral', 780: 'oralfacialdigital', 781: 'ornithine', 782: 'oropharyngeal', 783: 'osteochondromas', 784: 'osteodysplasia', 785: 'osteodysplastic', 786: 'osteolysis', 787: 'osteoporosis', 788: 'osteosarcoma', 789: 'outlet', 790: 'outlook', 791: 'ovarian', 792: 'overload', 793: 'ow', 794: 'p', 795: 'pad', 796: 'paget', 797: 'pagets', 798: 'pain', 799: 'palsies', 800: 'palsy', 801: 'pancreatitis', 802: 'panencephalitis', 803: 'paraganglioma', 804: 'paragangliomapheochromocytoma', 805: 'paralyses', 806: 'paralysis', 807: 'paranasal', 808: 'paraplegia', 809: 'parathyroid', 810: 'parkinsonism', 811: 'parkinsons', 812: 'partial', 813: 'peeling', 814: 'penile', 815: 'people', 816: 'periodic', 817: 'peripheral', 818: 'peters', 819: 'peutzjeghers', 820: 'pfeiffer', 821: 'phenylketonuria', 822: 'phosphate', 823: 'phosphoglycerate', 824: 'phosphoribosylpyrophosphate', 825: 'phosphoribosyltransferase', 826: 'piebaldism', 827: 'pierre', 828: 'pigmented', 829: 'pigmenti', 830: 'pigmentosa', 831: 'pigmentosum', 832: 'pikdelta', 833: 'pilomatricoma', 834: 'pitthopkins', 835: 'pituitary', 836: 'plasma', 837: 'platelet', 838: 'platyspondylic', 839: 'plus', 840: 'pmmcongenital', 841: 'pol', 842: 'poland', 843: 'polyangiitis', 844: 'polycystic', 845: 'polycythemia', 846: 'polyendocrinopathy', 847: 'polyglucosan', 848: 'polymicrogyria', 849: 'polyneuropathy', 850: 'polyposis', 851: 'pompe', 852: 'pontocerebellar', 853: 'popliteal', 854: 'porphyria', 855: 'postural', 856: 'potassiumaggravated', 857: 'potential', 858: 'pregnancy', 859: 'prescription', 860: 'pressure', 861: 'prevent', 862: 'primary', 863: 'primordial', 864: 'probably', 865: 'problems', 866: 'progeria', 867: 'progressive', 868: 'promyelocytic', 869: 'prostate', 870: 'protein', 871: 'proteinassociated', 872: 'pseudoobstruction', 873: 'psoriasis', 874: 'pterygium', 875: 'pulmonary', 876: 'pulmonic', 877: 'punctata', 878: 'purpura', 879: 'q', 880: 'qrelated', 881: 'qt', 882: 'quitting', 883: 'radius', 884: 'raggedred', 885: 'receptor', 886: 'receptorassociated', 887: 'rectal', 888: 'reductase', 889: 'related', 890: 'renal', 891: 'renpenning', 892: 'repetitive', 893: 'research', 894: 'resistance', 895: 'respiratory', 896: 'restless', 897: 'restriction', 898: 'reticularis', 899: 'retina', 900: 'retinal', 901: 'retinitis', 902: 'retinoblastoma', 903: 'retinoschisis', 904: 'retraction', 905: 'retroperitoneal', 906: 'rett', 907: 'rheumatoid', 908: 'rhizomelic', 909: 'rickets', 910: 'ring', 911: 'rippling', 912: 'risk', 913: 'risks', 914: 'roberts', 915: 'robin', 916: 'robinow', 917: 'rod', 918: 'rothmundthomson', 919: 'rotor', 920: 'rubinsteintaybi', 921: 'russellsilver', 922: 's', 923: 'saddan', 924: 'saethrechotzen', 925: 'salih', 926: 'salivary', 927: 'sandhoff', 928: 'sarcoma', 929: 'saybarberbieseckeryoungsimpson', 930: 'schilders', 931: 'schimke', 932: 'schindler', 933: 'schinzelgiedion', 934: 'schwartzjampel', 935: 'scleroderma', 936: 'sclerosing', 937: 'sclerosis', 938: 'scoliosis', 939: 'seizures', 940: 'sella', 941: 'semialdehyde', 942: 'seniorlken', 943: 'sensitivity', 944: 'sensorineural', 945: 'sensory', 946: 'sepiapterin', 947: 'septooptic', 948: 'sequence', 949: 'severe', 950: 'sex', 951: 'sheldonhall', 952: 'shingles', 953: 'short', 954: 'shortchain', 955: 'shprintzengoldberg', 956: 'shwachmandiamond', 957: 'sialic', 958: 'sialidosis', 959: 'sialuria', 960: 'sick', 961: 'sickle', 962: 'siderius', 963: 'sideroblastic', 964: 'silver', 965: 'simpsongolabibehmel', 966: 'sinus', 967: 'sitosterolemia', 968: 'sjgren', 969: 'sjgrenlarsson', 970: 'skeletal', 971: 'skin', 972: 'slcaassociated', 973: 'small', 974: 'smell', 975: 'smethyltransferase', 976: 'smithlemliopitz', 977: 'smithmagenis', 978: 'smoking', 979: 'snyderrobinson', 980: 'sostrelated', 981: 'sotos', 982: 'sox', 983: 'spasm', 984: 'spastic', 985: 'spectrum', 986: 'spherocytosis', 987: 'spheroids', 988: 'spina', 989: 'spinal', 990: 'spinocerebellar', 991: 'spondylocarpotarsal', 992: 'spondylocostal', 993: 'spondyloenchondrodysplasia', 994: 'spondyloepimetaphyseal', 995: 'spondyloepiphyseal', 996: 'spondyloperipheral', 997: 'spondylothoracic', 998: 'sponge', 999: 'sporadic', 1000: 'spread', 1001: 'squamous', 1002: 'stages', 1003: 'stargardt', 1004: 'stationary', 1005: 'steatocystoma', 1006: 'stem', 1007: 'stenosis', 1008: 'stevensjohnson', 1009: 'stickler', 1010: 'stimulation', 1011: 'stingassociated', 1012: 'storage', 1013: 'stormorken', 1014: 'stroke', 1015: 'strokelike', 1016: 'stromal', 1017: 'strudwick', 1018: 'sturgeweber', 1019: 'stvewiedemann', 1020: 'subacute', 1021: 'subcortical', 1022: 'succinatecoa', 1023: 'succinic', 1024: 'succinylcoaketoacid', 1025: 'sudden', 1026: 'sulfatase', 1027: 'superactivity', 1028: 'suppurativa', 1029: 'supravalvular', 1030: 'surfactant', 1031: 'surviving', 1032: 'swallowing', 1033: 'swyer', 1034: 'symptomps', 1035: 'symptoms', 1036: 'syncope', 1037: 'syndrome', 1038: 'syndromedermatopathia', 1039: 'syndromemyopathic', 1040: 'syndromes', 1041: 'syndrometoxic', 1042: 'syngaprelated', 1043: 'synostosis', 1044: 'synthase', 1045: 'synthetase', 1046: 'syrup', 1047: 'system', 1048: 'systemic', 1049: 'systems', 1050: 'szary', 1051: 'tachycardia', 1052: 'tangier', 1053: 'tarda', 1054: 'tarsalcarpal', 1055: 'taskspecific', 1056: 'taste', 1057: 'taysachs', 1058: 'tcell', 1059: 'telangiectasia', 1060: 'teratoid', 1061: 'testes', 1062: 'testicular', 1063: 'tethered', 1064: 'tetraamelia', 1065: 'tetrahydrobiopterin', 1066: 'tetrasomy', 1067: 'thalassemia', 1068: 'thanatophoric', 1069: 'that', 1070: 'the', 1071: 'thiamineresponsive', 1072: 'thiopurine', 1073: 'thoracic', 1074: 'thrombasthenia', 1075: 'thrombocythemia', 1076: 'thrombocytopenia', 1077: 'thrombocytopeniaabsent', 1078: 'thrombocytopenic', 1079: 'thrombotic', 1080: 'thymic', 1081: 'thymoma', 1082: 'thyroiditis', 1083: 'thyroxinebinding', 1084: 'tibial', 1085: 'tietz', 1086: 'timothy', 1087: 'tkrelated', 1088: 'to', 1089: 'todds', 1090: 'torrance', 1091: 'tourette', 1092: 'townesbrocks', 1093: 'tp', 1094: 'tract', 1095: 'transcarbamylase', 1096: 'transferase', 1097: 'transient', 1098: 'transthyretin', 1099: 'transverse', 1100: 'treacher', 1101: 'treatments', 1102: 'tremor', 1103: 'trials', 1104: 'trichoepithelioma', 1105: 'trichohepatoenteric', 1106: 'trichothiodystrophy', 1107: 'trifunctional', 1108: 'trigeminal', 1109: 'trimethylaminuria', 1110: 'triosephosphate', 1111: 'triple', 1112: 'trisomy', 1113: 'trophoblastic', 1114: 'troyer', 1115: 'tuberous', 1116: 'tubular', 1117: 'tumor', 1118: 'tumors', 1119: 'turner', 1120: 'type', 1121: 'tyrosine', 1122: 'tyrosinemia', 1123: 'ulcerative', 1124: 'unverrichtlundborg', 1125: 'urethral', 1126: 'urinary', 1127: 'urine', 1128: 'uromodulinassociated', 1129: 'usher', 1130: 'uterine', 1131: 'uvsensitive', 1132: 'v', 1133: 'vacterl', 1134: 'van', 1135: 'vanishing', 1136: 'variant', 1137: 'vasculitis', 1138: 'vasculopathy', 1139: 'venoocclusive', 1140: 'venous', 1141: 'vera', 1142: 'very', 1143: 'vi', 1144: 'vii', 1145: 'virus', 1146: 'vitamin', 1147: 'vitelliform', 1148: 'vitiligo', 1149: 'vldlrassociated', 1150: 'vohwinkel', 1151: 'von', 1152: 'vries', 1153: 'vulvar', 1154: 'waardenburg', 1155: 'wagner', 1156: 'wagr', 1157: 'waldenstrm', 1158: 'walkerwarburg', 1159: 'wall', 1160: 'warfarin', 1161: 'warsaw', 1162: 'weaver', 1163: 'weillmarchesani', 1164: 'weissenbacherzweymller', 1165: 'werner', 1166: 'wernickekorsakoff', 1167: 'weyers', 1168: 'what', 1169: 'whiplash', 1170: 'white', 1171: 'who', 1172: 'willebrand', 1173: 'williams', 1174: 'wilson', 1175: 'winchester', 1176: 'wiskottaldrich', 1177: 'with', 1178: 'wolffparkinsonwhite', 1179: 'wolfhirschhorn', 1180: 'wolfram', 1181: 'wolman', 1182: 'woolly', 1183: 'woude', 1184: 'x', 1185: 'xanthinuria', 1186: 'xeroderma', 1187: 'xlinked', 1188: 'xx', 1189: 'xxyy', 1190: 'xyy', 1191: 'y', 1192: 'zaprelated', 1193: 'zellweger'}\n"
     ]
    }
   ],
   "source": [
    "#creating a dictionary for index to word for source and target vocabulary\n",
    "source_idx2word= dict([(i, word) for word, i in  source_word2idx.items()])\n",
    "print(source_idx2word)\n",
    "target_idx2word =dict([(i, word) for word, i in target_word2idx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the data\n",
    "lines = shuffle(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3999,), (41,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - Test Split\n",
    "X, y = lines.source, lines.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.01)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/54880279/how-to-handle-invalid-argument-error-in-keras\n",
    "# Input tokens for encoder\n",
    "num_encoder_tokens=len(source_words) +1\n",
    "# Input tokens for decoder zero padded\n",
    "num_decoder_tokens=len(target_words) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 180):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_source_length),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_target_length),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_target_length, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                        encoder_input_data[i, t] = source_word2idx[word] \n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_word2idx[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        #print(word)\n",
    "                        decoder_target_data[i, t - 1, target_word2idx[word]] = 1.\n",
    "                    \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "latent_dim=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that takes encoder and decoder input \n",
    "# to output decoder_outputs\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train) # Total Training samples\n",
    "val_samples = len(X_test)    # Total validation or test samples\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hasibur1\\Anaconda3_\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 44s 1s/step - loss: 2.1269 - acc: 0.1087 - val_loss: 0.6163 - val_acc: 0.1203\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 1.8377 - acc: 0.1307 - val_loss: 0.5869 - val_acc: 0.1693\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 1.7288 - acc: 0.1687 - val_loss: 0.5528 - val_acc: 0.2673\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 1.5837 - acc: 0.2521 - val_loss: 0.5176 - val_acc: 0.3385\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 38s 1s/step - loss: 1.4481 - acc: 0.3183 - val_loss: 0.4882 - val_acc: 0.3831\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 1.3321 - acc: 0.3712 - val_loss: 0.4605 - val_acc: 0.4098\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 1.2406 - acc: 0.4120 - val_loss: 0.4438 - val_acc: 0.4454\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 1.1640 - acc: 0.4424 - val_loss: 0.4305 - val_acc: 0.4543\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 1.0998 - acc: 0.4635 - val_loss: 0.4211 - val_acc: 0.4655\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 1.0436 - acc: 0.4846 - val_loss: 0.4120 - val_acc: 0.4744\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.9978 - acc: 0.5015 - val_loss: 0.4028 - val_acc: 0.4855\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.9500 - acc: 0.5173 - val_loss: 0.3985 - val_acc: 0.4900\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.9102 - acc: 0.5283 - val_loss: 0.3933 - val_acc: 0.4944\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.8731 - acc: 0.5392 - val_loss: 0.3870 - val_acc: 0.4944\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.8429 - acc: 0.5490 - val_loss: 0.3841 - val_acc: 0.4900\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.8128 - acc: 0.5582 - val_loss: 0.3809 - val_acc: 0.4922\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.7778 - acc: 0.5697 - val_loss: 0.3780 - val_acc: 0.5011\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.7514 - acc: 0.5784 - val_loss: 0.3776 - val_acc: 0.4944\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.7290 - acc: 0.5855 - val_loss: 0.3748 - val_acc: 0.5011\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.7034 - acc: 0.5930 - val_loss: 0.3739 - val_acc: 0.5078\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.6798 - acc: 0.6028 - val_loss: 0.3714 - val_acc: 0.5033\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.6577 - acc: 0.6107 - val_loss: 0.3702 - val_acc: 0.5100\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.6358 - acc: 0.6187 - val_loss: 0.3690 - val_acc: 0.5122\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.6162 - acc: 0.6253 - val_loss: 0.3676 - val_acc: 0.5100\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.5975 - acc: 0.6344 - val_loss: 0.3665 - val_acc: 0.5189\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.5772 - acc: 0.6437 - val_loss: 0.3706 - val_acc: 0.5056\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.5539 - acc: 0.6561 - val_loss: 0.3690 - val_acc: 0.5078\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.5379 - acc: 0.6641 - val_loss: 0.3720 - val_acc: 0.5189\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.5216 - acc: 0.6736 - val_loss: 0.3717 - val_acc: 0.5167\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.5016 - acc: 0.6866 - val_loss: 0.3712 - val_acc: 0.5100\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.4864 - acc: 0.6967 - val_loss: 0.3731 - val_acc: 0.4922\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.4689 - acc: 0.7066 - val_loss: 0.3734 - val_acc: 0.5100\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.4654 - acc: 0.7169 - val_loss: 0.3734 - val_acc: 0.4989\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.4399 - acc: 0.7259 - val_loss: 0.3730 - val_acc: 0.5145\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 38s 1s/step - loss: 0.4234 - acc: 0.7360 - val_loss: 0.3752 - val_acc: 0.5145\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.4092 - acc: 0.7454 - val_loss: 0.3787 - val_acc: 0.5189\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.3936 - acc: 0.7557 - val_loss: 0.3826 - val_acc: 0.5212\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.3795 - acc: 0.7642 - val_loss: 0.3796 - val_acc: 0.5256\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.3664 - acc: 0.7734 - val_loss: 0.3794 - val_acc: 0.5212\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.3526 - acc: 0.7821 - val_loss: 0.3797 - val_acc: 0.5212\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 43s 1s/step - loss: 0.3412 - acc: 0.7894 - val_loss: 0.3812 - val_acc: 0.5167\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 43s 1s/step - loss: 0.3277 - acc: 0.7979 - val_loss: 0.3832 - val_acc: 0.5056\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.3173 - acc: 0.8060 - val_loss: 0.3842 - val_acc: 0.5122\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.3052 - acc: 0.8136 - val_loss: 0.3871 - val_acc: 0.5100\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.2940 - acc: 0.8205 - val_loss: 0.3899 - val_acc: 0.5189\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.2826 - acc: 0.8281 - val_loss: 0.3877 - val_acc: 0.5145\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 43s 1s/step - loss: 0.2725 - acc: 0.8357 - val_loss: 0.3877 - val_acc: 0.5167\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.2630 - acc: 0.8418 - val_loss: 0.3883 - val_acc: 0.5100\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.2513 - acc: 0.8485 - val_loss: 0.3963 - val_acc: 0.5078\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 43s 1s/step - loss: 0.2423 - acc: 0.8538 - val_loss: 0.4010 - val_acc: 0.5145\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.2331 - acc: 0.8614 - val_loss: 0.3973 - val_acc: 0.5189\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.2244 - acc: 0.8651 - val_loss: 0.4019 - val_acc: 0.5212\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.2149 - acc: 0.8727 - val_loss: 0.3988 - val_acc: 0.5189\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 45s 1s/step - loss: 0.2066 - acc: 0.8773 - val_loss: 0.3982 - val_acc: 0.5234\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1981 - acc: 0.8841 - val_loss: 0.3976 - val_acc: 0.5234\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.1908 - acc: 0.8881 - val_loss: 0.4016 - val_acc: 0.5145\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.1827 - acc: 0.8940 - val_loss: 0.4045 - val_acc: 0.5122\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.1756 - acc: 0.8990 - val_loss: 0.4082 - val_acc: 0.5167\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 43s 1s/step - loss: 0.1672 - acc: 0.9042 - val_loss: 0.4106 - val_acc: 0.5189\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1599 - acc: 0.9102 - val_loss: 0.4112 - val_acc: 0.5234\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.1535 - acc: 0.9150 - val_loss: 0.4155 - val_acc: 0.5122\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.1470 - acc: 0.9188 - val_loss: 0.4147 - val_acc: 0.5212\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 40s 1s/step - loss: 0.1399 - acc: 0.9244 - val_loss: 0.4144 - val_acc: 0.5323\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.1344 - acc: 0.9280 - val_loss: 0.4145 - val_acc: 0.5323\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.1306 - acc: 0.9333 - val_loss: 0.4170 - val_acc: 0.5167\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.1220 - acc: 0.9371 - val_loss: 0.4219 - val_acc: 0.5367\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.1169 - acc: 0.9401 - val_loss: 0.4227 - val_acc: 0.5323\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.1110 - acc: 0.9442 - val_loss: 0.4268 - val_acc: 0.5256\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.1052 - acc: 0.9478 - val_loss: 0.4328 - val_acc: 0.5189\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.0996 - acc: 0.9525 - val_loss: 0.4285 - val_acc: 0.5167\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.0952 - acc: 0.9546 - val_loss: 0.4342 - val_acc: 0.5145\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.0901 - acc: 0.9585 - val_loss: 0.4378 - val_acc: 0.5033\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.0857 - acc: 0.9609 - val_loss: 0.4334 - val_acc: 0.5167\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.0812 - acc: 0.9636 - val_loss: 0.4362 - val_acc: 0.5056\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 43s 1s/step - loss: 0.0777 - acc: 0.9668 - val_loss: 0.4396 - val_acc: 0.5122\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.0729 - acc: 0.9700 - val_loss: 0.4448 - val_acc: 0.5011\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.0693 - acc: 0.9711 - val_loss: 0.4474 - val_acc: 0.4989\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 44s 1s/step - loss: 0.0652 - acc: 0.9753 - val_loss: 0.4452 - val_acc: 0.5100\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.0617 - acc: 0.9760 - val_loss: 0.4468 - val_acc: 0.4967\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.0588 - acc: 0.9778 - val_loss: 0.4537 - val_acc: 0.4989\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.0549 - acc: 0.9804 - val_loss: 0.4537 - val_acc: 0.5011\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.0519 - acc: 0.9819 - val_loss: 0.4524 - val_acc: 0.5122\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.0490 - acc: 0.9833 - val_loss: 0.4555 - val_acc: 0.5011\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.0460 - acc: 0.9850 - val_loss: 0.4589 - val_acc: 0.5189\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.0439 - acc: 0.9853 - val_loss: 0.4548 - val_acc: 0.5189\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.0409 - acc: 0.9870 - val_loss: 0.4531 - val_acc: 0.5011\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.0385 - acc: 0.9882 - val_loss: 0.4570 - val_acc: 0.5011\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 38s 1s/step - loss: 0.0366 - acc: 0.9888 - val_loss: 0.4584 - val_acc: 0.4989\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.0342 - acc: 0.9900 - val_loss: 0.4633 - val_acc: 0.5011\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.0317 - acc: 0.9905 - val_loss: 0.4714 - val_acc: 0.4967\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.0298 - acc: 0.9915 - val_loss: 0.4630 - val_acc: 0.5056\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.0285 - acc: 0.9916 - val_loss: 0.4686 - val_acc: 0.5122\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.0259 - acc: 0.9922 - val_loss: 0.4722 - val_acc: 0.5100\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.0251 - acc: 0.9926 - val_loss: 0.4713 - val_acc: 0.5189\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.0236 - acc: 0.9930 - val_loss: 0.4816 - val_acc: 0.5122\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.0221 - acc: 0.9931 - val_loss: 0.4833 - val_acc: 0.5056\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.0210 - acc: 0.9941 - val_loss: 0.4855 - val_acc: 0.5100\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 40s 1s/step - loss: 0.0201 - acc: 0.9940 - val_loss: 0.4887 - val_acc: 0.5145\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.0181 - acc: 0.9949 - val_loss: 0.4878 - val_acc: 0.4944\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 39s 1s/step - loss: 0.0168 - acc: 0.9948 - val_loss: 0.4918 - val_acc: 0.5100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e25b61c748>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = train_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights_0epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('nmt_weights_0epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"Context vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_state_input = [decoder_state_input_h, decoder_state_input_c]\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_input)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_state_input,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of \n",
    "    #target sequence with the start character.\n",
    "    target_seq[0, 0] = target_word2idx['START_']\n",
    "# Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "# Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word =target_idx2word[sampled_token_index]\n",
    "        decoded_sentence += ' '+ sampled_word\n",
    "# Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == '_END' or\n",
    "           len(decoded_sentence) > 120):\n",
    "            stop_condition = True\n",
    "# Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "# Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Source sentence: what are the genetic changes related to head and neck squamous cell carcinoma\n",
      "Actual Target Translation:  hnscc is caused by a variety of factors that can alter the dna in cells \n",
      "Predicted Target Translation:  hnscc is caused by a variety of factors that can alter the dna in cells \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input Source sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Target Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Target Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Source sentence: what is are hereditary sensory neuropathy type ia\n",
      "Actual Target Translation:  hereditary sensory neuropathy type ia is a condition characterized by nerve abnormalities in the legs and feet \n",
      "Predicted Target Translation:  stage istage iistage iii \n"
     ]
    }
   ],
   "source": [
    "test_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
    "k=10\n",
    "k+=1\n",
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input Source sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual Target Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted Target Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
